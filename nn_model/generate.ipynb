{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Keypoints Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### W207 Spring 2022 Section 10 \n",
    "##### Team 4: Eric Sun, Jiayi Hu, Sridhar Chadalavada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "We are using the Kaggle data set for [Facial Keypoints Detection](https://www.kaggle.com/c/facial-keypoints-detection/overview) to experiment and build models that detect the locations of up to 30 keypoints on images of faces. Facial keypoint detection in images has a variety of applications such as image tagging, biometrics, or psychological and clinical medical diagnosis.\n",
    "\n",
    "The facial keypoints are primarily features dividing the face sagittally, for example the centers of the left and right eyes, with a smaller number of features in the midline, such as the tip of the nose. We will be exploring convolutional neural networks (CNNs) and the impacts of tuning parameters and hyperparameters to improve score and mitigate overfitting as well as comparing other models that may be less performant.\n",
    "\n",
    "#### Data\n",
    "The Kaggle data sets include labeled Training and unlabeled Testing data sets. Because we do not have access to the Test labels, the predicted Test labels of our final model will be scored within Kaggle, which will evaluate our submission against those of other participants based on the root mean square errors of the predicted and original values. Our Training data includes 7,049 images that we will use to divide into Training and Development sets, and our Test data includes 1,783 images. The images are represented as a grid of 96x96 pixels in the range of (0, 255) with each keypoint defined by an x and y position in that grid.\n",
    "\n",
    "#### Internal Project Milestones\n",
    "3/13: Baseline Submission  \n",
    "3/20: Individual research and analysis into CNN modeling and transformation  \n",
    "3/27: Identify chosen model parameters and experiments and merge for notebook report  \n",
    "4/3: Complete final notebook  \n",
    "4/10: Complete final presentation  \n",
    "4/14: Final deliverable and in-class presentation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.width = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ZipFile('./facial-keypoints-detection.zip')\n",
    "train_zip = ZipFile(z.open('training.zip'))\n",
    "test_zip = ZipFile(z.open('test.zip'))\n",
    "\n",
    "train = pd.read_csv(train_zip.open('training.csv'))\n",
    "print('Initial Training', train.shape)\n",
    "\n",
    "test = pd.read_csv(test_zip.open('test.csv'), index_col=0)\n",
    "print('Initial Test', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data\n",
    "\n",
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "fig.add_subplot(121)\n",
    "\n",
    "train.isnull().sum().plot(kind='bar')\n",
    "plt.title('Before')\n",
    "plt.ylim(0, len(train))\n",
    "\n",
    "train_no_na = train.dropna(axis=0).copy().reset_index(drop=True)\n",
    "# train_no_na = train.fillna(value=0).copy()\n",
    "# train_no_na = train.fillna(method='ffill').copy()\n",
    "\n",
    "fig.add_subplot(122)\n",
    "train_no_na.isnull().sum().plot(kind='bar')\n",
    "plt.title('After')\n",
    "plt.ylim(0, len(train_no_na))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify image data in-place\n",
    "\n",
    "def format_string_into_list(target, from_col):\n",
    "\ttarget['image_data'] = target[from_col].map(lambda x: np.array([(int(y) if y != '' else 0) for y in x.split(' ')]))\n",
    "\tassert len(target['image_data'].map(len).unique()) == 1, f'Missing or uneven lengths in image data: {target.image_data.map(len)}' \n",
    "\tassert min(target['image_data'].map(min)) >= 0, 'Negative values in image data'\n",
    "\tassert max(target['image_data'].map(max)) < 256, 'Unexpectedly large values in image data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_string_into_list(train_no_na, 'Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show faces\n",
    "def show_faces(target, height, width):\n",
    "\trandom_indexes = np.random.default_rng().choice(target.index, width * height, False)\n",
    "\tfig = plt.figure(figsize=(width * 2.5, height * 2.5))\n",
    "\tfor i in range(width * height):\n",
    "\t\tfig.add_subplot(height, width, i + 1)\n",
    "\t\tplt.imshow(target.at[random_indexes[i], 'image_data'].reshape(96, 96), cmap='gray')\n",
    "\t\tkeypoints = target.iloc[random_indexes[i], :~1].to_numpy()\n",
    "\t\tplt.scatter(keypoints[0::2], keypoints[1::2], marker='+')\n",
    "\t\tplt.xticks([])\n",
    "\t\tplt.yticks([])\n",
    "\tplt.show()\n",
    "\t\n",
    "show_faces(train_no_na, 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more about model building here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\ttf.keras.layers.Flatten(input_shape=(96, 96, 1)),\n",
    "\ttf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "\ttf.keras.layers.Dropout(0.1),\n",
    "\ttf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "\ttf.keras.layers.Dense(30)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(train_no_na.image_data.to_numpy()).reshape(-1, 96, 96)\n",
    "y = np.concatenate(train_no_na.iloc[:,:~1].to_numpy()).reshape(-1, len(train_no_na.columns) - 2)\n",
    "print(x.shape, y.shape)\n",
    "model.fit(x, y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_string_into_list(test, 'Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(test.image_data.to_numpy()).reshape(-1, 96, 96)\n",
    "y = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show faces\n",
    "\n",
    "show_faces(pd.concat([pd.DataFrame(y), test.reset_index(drop=True)], axis=1), 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model into TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, 'tfjs_model', weight_shard_size_bytes=999999999)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07d859045644b4eb5a2aed015b31bfa06f0d64e50442783bd76f310575af0fff"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf37]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
