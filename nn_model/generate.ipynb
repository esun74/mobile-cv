{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Keypoints Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### W207 Spring 2022 Section 10 \n",
    "##### Team 4: Eric Sun, Jiayi Hu, Sridhar Chadalavada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "We are using the Kaggle data set for [Facial Keypoints Detection](https://www.kaggle.com/c/facial-keypoints-detection/overview) to experiment and build models that detect the locations of up to 30 keypoints on images of faces. Facial keypoint detection in images has a variety of applications such as image tagging, biometrics, or psychological and clinical medical diagnosis.\n",
    "\n",
    "The facial keypoints are primarily features dividing the face sagitally, for example the centers of the left and right eyes, with a smaller number of features in the midline, such as the tip of the nose. We will be exploring convolutional neural networks (CNNs) and the impacts of tuning parameters and hyperparameters to improve score and mitigate overfitting as well as comparing other models that may be less performant.\n",
    "\n",
    "#### Data\n",
    "The Kaggle data sets include labeled Training and unlabeled Testing data sets. Because we do not have access to the Test labels, the predicted Test labels of our final model will be scored within Kaggle, which will evaluate our submission against those of other participants based on the root mean square errors of the predicted and original values. Our Training data includes 7,049 images that we will use to divide into Training and Development sets, and our Test data includes 1,783 images. The images are represented as a grid of 96x96 pixels in the range of (0, 255) with each keypoint defined by an x and y position in that grid.\n",
    "\n",
    "#### Internal Project Milestones\n",
    "3/13: Baseline Submission  \n",
    "3/20: Individual research and analysis into CNN modeling and transformation  \n",
    "3/27: Identify chosen model parameters and experiments and merge for notebook report  \n",
    "4/3: Complete final notebook  \n",
    "4/10: Complete final presentation  \n",
    "4/14: Final deliverable and in-class presentation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.width = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_lookup_table = pd.read_csv('./IdLookupTable.csv')\n",
    "\n",
    "train = pd.read_csv('./training.csv')\n",
    "print('Initial Training', train.shape)\n",
    "\n",
    "test = pd.read_csv('./test.csv', index_col=0)\n",
    "print('Initial Test', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data\n",
    "\n",
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "\n",
    "train.isnull().sum().plot(kind='bar')\n",
    "plt.ylim(0, len(train))\n",
    "plt.show()\n",
    "\n",
    "# different options to fix na values\n",
    "# inplace saves space but I want the flexibility to switch later without reloading the original dataset\n",
    "\n",
    "# train_no_na = train.dropna(axis=0).copy().reset_index(drop=True)\n",
    "# train_no_na = train.fillna(value=0).copy()\n",
    "train_no_na = train.fillna(method='ffill').copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify image data in-place\n",
    "\n",
    "def format_string_into_list(target, from_col):\n",
    "\ttarget['image_data'] = target[from_col].map(lambda x: np.array([int(y) for y in x.split(' ')]))\n",
    "\tassert len(target['image_data'].map(len).unique()) == 1, f'Missing or uneven lengths in image data: {target.image_data.map(len)}' \n",
    "\tassert min(target['image_data'].map(min)) >= 0, 'Negative values in image data'\n",
    "\tassert max(target['image_data'].map(max)) < 256, 'Unexpectedly large values in image data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_string_into_list(train_no_na, 'Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show face\n",
    "\n",
    "def plot_face(index):\n",
    "\tplt.imshow(train_no_na.at[index, 'image_data'].reshape(96, 96), cmap='gray')\n",
    "\tkeypoints = train_no_na.iloc[index, :~1].to_numpy()\n",
    "\tplt.scatter(keypoints[0::2], keypoints[1::2])\n",
    "\tplt.xticks([])\n",
    "\tplt.yticks([])\n",
    "\tplt.show()\n",
    "\n",
    "interactive(plot_face, index=train_no_na.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\ttf.keras.layers.Flatten(input_shape=(96, 96, 1)),\n",
    "\t\ttf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "\t\ttf.keras.layers.Dropout(0.1),\n",
    "\t\ttf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "\t\ttf.keras.layers.Dense(30)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(train_no_na.image_data.to_numpy()).reshape(-1, 96, 96)\n",
    "y = np.concatenate(train_no_na.iloc[:,:~1].to_numpy()).reshape(-1, len(train_no_na.columns) - 2)\n",
    "print(x.shape, y.shape)\n",
    "model.fit(x, y, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_string_into_list(test, 'Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(test.image_data.to_numpy()).reshape(-1, 96, 96)\n",
    "y = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show face\n",
    "\n",
    "def plot_face2(index):\n",
    "\tplt.imshow(test.at[index, 'image_data'].reshape(96, 96), cmap='gray')\n",
    "\tpredicted_kp = y[index]\n",
    "\tplt.scatter(predicted_kp[0::2], predicted_kp[1::2], color='red')\n",
    "\tplt.xticks([])\n",
    "\tplt.yticks([])\n",
    "\tplt.show()\n",
    "\n",
    "interactive(plot_face2, index=test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model into TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, 'tfjs_model', weight_shard_size_bytes=999999999)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2e1a8a09c6f509f76675edcf174a63ac69d3e45e96543f6baad2bdc5f08cb6a"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf37]",
   "language": "python",
   "name": "conda-env-tf37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
